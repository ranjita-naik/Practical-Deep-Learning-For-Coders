{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Linear models with CNN features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "%matplotlib inline\n",
    "from __future__ import division,print_function\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt\n",
    "import utils; reload(utils)\n",
    "from utils import plots, get_batches, plot_confusion_matrix, get_data\n",
    "\n",
    "from numpy.random import random, permutation\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear models in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0757,  0.4879],\n",
       "       [ 0.2688,  0.8152],\n",
       "       [ 0.3069,  0.6867],\n",
       "       [ 0.2403,  0.8383],\n",
       "       [ 0.29  ,  0.7524],\n",
       "       [ 0.7629,  0.7809],\n",
       "       [ 0.5818,  0.6132],\n",
       "       [ 0.4597,  0.4712],\n",
       "       [ 0.1095,  0.7411],\n",
       "       [ 0.8669,  0.9558],\n",
       "       [ 0.8582,  0.943 ],\n",
       "       [ 0.9304,  0.3402],\n",
       "       [ 0.5427,  0.5043],\n",
       "       [ 0.6805,  0.2243],\n",
       "       [ 0.5752,  0.5126],\n",
       "       [ 0.8578,  0.5433],\n",
       "       [ 0.1836,  0.092 ],\n",
       "       [ 0.8416,  0.0233],\n",
       "       [ 0.9469,  0.2414],\n",
       "       [ 0.9445,  0.8352],\n",
       "       [ 0.4676,  0.8094],\n",
       "       [ 0.1282,  0.0647],\n",
       "       [ 0.3009,  0.6987],\n",
       "       [ 0.4157,  0.3149],\n",
       "       [ 0.5266,  0.3608],\n",
       "       [ 0.9487,  0.8267],\n",
       "       [ 0.5142,  0.6453],\n",
       "       [ 0.826 ,  0.3038],\n",
       "       [ 0.6361,  0.171 ],\n",
       "       [ 0.05  ,  0.5461]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = random((30,2))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.6151,  3.9833,  3.6738,  3.9955,  3.8374,  4.8685,  4.0032,  3.3329,  3.4422,  5.6012,\n",
       "        5.5452,  3.8814,  3.5983,  3.0339,  3.6882,  4.3455,  1.6432,  2.7531,  3.6179,  5.3946,\n",
       "        4.3636,  1.4507,  3.6978,  2.7762,  3.1358,  5.3775,  3.9641,  3.5633,  2.7853,  2.7383])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.dot(x,[2,3]) + 1\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm = Sequential([ Dense(1, input_shape=(2,)) ])\n",
    "lm.compile(optimizer=SGD(lr=0.1), loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.496160507202148"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's evaluate the model, note that weights aren't learnt yet, \n",
    "# this evaluation is based on the initial value of the weights\n",
    "lm.evaluate(x, y, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "30/30 [==============================] - 0s - loss: 0.7544     \n",
      "Epoch 2/5\n",
      "30/30 [==============================] - 0s - loss: 0.0702     \n",
      "Epoch 3/5\n",
      "30/30 [==============================] - 0s - loss: 0.0408     \n",
      "Epoch 4/5\n",
      "30/30 [==============================] - 0s - loss: 0.0195     \n",
      "Epoch 5/5\n",
      "30/30 [==============================] - 0s - loss: 0.0096     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16108240>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model for 5 epochs\n",
    "lm.fit(x, y, nb_epoch=5, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010440172627568245"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's evaluate again\n",
    "lm.evaluate(x, y, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.8346],\n",
       "        [ 2.8365]], dtype=float32), array([ 1.2551], dtype=float32)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare the weights with the ones we used while synthesizing the data (2, 3, 1)\n",
    "lm.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Train a linear model on imagenet predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path = \"data/dogscats/sample/\"\n",
    "path = \"data/dogscats/\"\n",
    "model_path = path + 'models/'\n",
    "if not os.path.exists(model_path): os.mkdir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vgg16 import Vgg16\n",
    "vgg = Vgg16()\n",
    "model = vgg.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get the true label for each image\n",
    "2. Get 1000 imagenet category prediction for each image\n",
    "3. Feed these predictions to linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 23000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_batches = get_batches(path+'valid', shuffle=False, batch_size=1)\n",
    "train_batches = get_batches(path+'train', shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz\n",
    "def save_array(fname, arr): c=bcolz.carray(arr, rootdir=fname, mode='w'); c.flush()\n",
    "def load_array(fname): return bcolz.open(fname)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 23000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_data = get_data(path+'valid')\n",
    "train_data = get_data(path+'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save_array(model_path+'train_data.bc', trn_data)\n",
    "#save_array(model_path+'valid_data.bc', val_data)\n",
    "\n",
    "#train_data = load_array(model_path+'train_data.bc')\n",
    "#val_data = load_array(model_path+'valid_data.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehot(x): return np.array(OneHotEncoder().fit_transform(x.reshape(-1,1)).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_classes = val_batches.classes\n",
    "train_classes = train_batches.classes\n",
    "\n",
    "val_labels = onehot(val_classes)\n",
    "train_labels = onehot(train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_classes[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = model.predict(train_data, batch_size=batch_size)\n",
    "val_features = model.predict(val_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save_array(model_path+'train_lastlayer_features.bc', trn_features)\n",
    "# save_array(model_path+'valid_lastlayer_features.bc', val_features)\n",
    "\n",
    "# trn_features = load_array(model_path+'train_lastlayer_features.bc')\n",
    "# val_features = load_array(model_path+'valid_lastlayer_features.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1000 features, 2 outputs\n",
    "lm = Sequential([ Dense(2,activation='softmax', input_shape=(1000,)) ])\n",
    "lm.compile(optimizer=RMSprop(lr=0.1), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "23000/23000 [==============================] - 2s - loss: 0.1005 - acc: 0.9713 - val_loss: 0.1282 - val_acc: 0.9670\n",
      "Epoch 2/5\n",
      "23000/23000 [==============================] - 2s - loss: 0.1052 - acc: 0.9752 - val_loss: 0.1361 - val_acc: 0.9705\n",
      "Epoch 3/5\n",
      "23000/23000 [==============================] - 2s - loss: 0.1097 - acc: 0.9760 - val_loss: 0.1461 - val_acc: 0.9710\n",
      "Epoch 4/5\n",
      "23000/23000 [==============================] - 2s - loss: 0.1172 - acc: 0.9770 - val_loss: 0.1557 - val_acc: 0.9715\n",
      "Epoch 5/5\n",
      "23000/23000 [==============================] - 2s - loss: 0.1210 - acc: 0.9777 - val_loss: 0.1677 - val_acc: 0.9715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xd1ab1048>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(train_features, train_labels, nb_epoch=5, batch_size=batch_size, validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_6 (Dense)                  (None, 2)             2002        dense_input_3[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 2,002\n",
      "Trainable params: 2,002\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Retrain last layer of vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pop the last layer and disable re-training all other layers\n",
    "model.pop()\n",
    "for layer in model.layers:  layer.trainable = False\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add the new layer\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen=image.ImageDataGenerator()\n",
    "train_batches = gen.flow(train_data, train_labels, batch_size=batch_size, shuffle=True)\n",
    "val_batches = gen.flow(val_data, val_labels, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model(model, batches, val_batches, nb_epoch=1):\n",
    "    model.fit_generator(batches, samples_per_epoch=batches.n, nb_epoch=nb_epoch, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = RMSprop(lr=0.1)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "23000/23000 [==============================] - 904s - loss: 2.5893 - acc: 0.8385 - val_loss: 0.3863 - val_acc: 0.9760\n",
      "Epoch 2/2\n",
      "23000/23000 [==============================] - 902s - loss: 0.4641 - acc: 0.9708 - val_loss: 0.3708 - val_acc: 0.9770\n"
     ]
    }
   ],
   "source": [
    "fit_model(model, train_batches, val_batches, nb_epoch=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-training multiple layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#let's skip conv layers\n",
    "layers = model.layers\n",
    "# get the index of first dense layer and set this and subsquent layer to be trainable\n",
    "first_dense_idx = [index for index, layer in enumerate(layers) if type(layer) is Dense][0]\n",
    "for layer in layers[first_dense_idx:] : layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "23000/23000 [==============================] - 908s - loss: 0.3897 - acc: 0.9754 - val_loss: 0.3075 - val_acc: 0.9805\n",
      "Epoch 2/3\n",
      "23000/23000 [==============================] - 906s - loss: 0.4246 - acc: 0.9731 - val_loss: 0.3823 - val_acc: 0.9760\n",
      "Epoch 3/3\n",
      "23000/23000 [==============================] - 906s - loss: 0.3715 - acc: 0.9766 - val_loss: 0.3282 - val_acc: 0.9795\n"
     ]
    }
   ],
   "source": [
    "K.set_value(opt.lr, 0.01)\n",
    "fit_model(model, train_batches, val_batches, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "23000/23000 [==============================] - 906s - loss: 0.3755 - acc: 0.9761 - val_loss: 0.3225 - val_acc: 0.9795\n",
      "Epoch 2/4\n",
      "23000/23000 [==============================] - 906s - loss: 0.3870 - acc: 0.9755 - val_loss: 0.3304 - val_acc: 0.9795\n",
      "Epoch 3/4\n",
      "23000/23000 [==============================] - 905s - loss: 0.3823 - acc: 0.9757 - val_loss: 0.3292 - val_acc: 0.9795\n",
      "Epoch 4/4\n",
      "23000/23000 [==============================] - 907s - loss: 0.3724 - acc: 0.9766 - val_loss: 0.3304 - val_acc: 0.9795\n"
     ]
    }
   ],
   "source": [
    "# let's re-train some of the conv layers as well\n",
    "for layer in layers[12:]: layer.trainable=True\n",
    "# decrease the learning rate further\n",
    "K.set_value(opt.lr, 0.001)\n",
    "fit_model(model, train_batches, val_batches, 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
